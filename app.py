import streamlit as st
import pandas as pd
from hellowork import scrape_hellowork_playwright
from indeed import scrape_indeed
import random
import time

# -----------------------------
# âš™ï¸ Configuration de la page Streamlit
# -----------------------------
st.set_page_config(page_title="Scrappeur d'offres", page_icon="ğŸ’¼", layout="centered")

st.title("ğŸ’¼ Scrappeur d'offres d'emploi multi-sites")
st.markdown("""
Ce scrappeur recherche automatiquement des offres dâ€™emploi sur plusieurs sites :  
**HelloWork**, **Indeed** *(et bientÃ´t WelcomeToTheJungle, Jobteaser...)*.
""")

# -----------------------------
# ğŸ¯ EntrÃ©es utilisateur
# -----------------------------
keyword = st.text_input("ğŸ” Mot-clÃ©", "Web developer")
location = st.text_input("ğŸ“ Ville", "Toulouse")
pages = st.slider("ğŸ“„ Nombre de pages Ã  parcourir", 1, 10, 3)
filtre_alternance = st.checkbox("ğŸ“Œ Filtrer uniquement Alternance", value=True)

# Choix des sites Ã  scraper
sites = st.multiselect(
    "ğŸŒ Choisir les sites Ã  scraper :",
    ["HelloWork", "Indeed"],
    default=["HelloWork", "Indeed"]
)

# -----------------------------
# ğŸš€ Bouton de lancement du scraping
# -----------------------------
if st.button("ğŸš€ Lancer le scraping"):
    with st.spinner("Scraping en cours..."):
        dfs = []

        # Scraper HelloWork
        if "HelloWork" in sites:
            st.info("ğŸ” Scraping HelloWork en cours...")
            try:
                df_hellowork = scrape_hellowork_playwright(keyword, location, pages, filtre_alternance)
                if not df_hellowork.empty:
                    dfs.append(df_hellowork)
                    st.success(f"âœ… {len(df_hellowork)} offres rÃ©cupÃ©rÃ©es depuis HelloWork")
                else:
                    st.warning("Aucune offre trouvÃ©e sur HelloWork.")
            except Exception as e:
                st.error(f"Erreur sur HelloWork : {e}")
            time.sleep(random.uniform(1, 2))

        # Scraper Indeed
        if "Indeed" in sites:
            st.info("ğŸ” Scraping Indeed en cours...")
            try:
                df_indeed = scrape_indeed(keyword, location, pages)
                if not df_indeed.empty:
                    dfs.append(df_indeed)
                    st.success(f"âœ… {len(df_indeed)} offres rÃ©cupÃ©rÃ©es depuis Indeed")
                else:
                    st.warning("Aucune offre trouvÃ©e sur Indeed.")
            except Exception as e:
                st.error(f"Erreur sur Indeed : {e}")
            time.sleep(random.uniform(1, 2))

        # Fusion des rÃ©sultats
        if dfs:
            df_total = pd.concat(dfs, ignore_index=True)
            df_total.drop_duplicates(subset=["Titre", "Entreprise"], inplace=True)

            st.success(f"ğŸ‰ Total : {len(df_total)} offres trouvÃ©es sur {', '.join(sites)}")
            st.dataframe(df_total)

            # Statistiques rapides
            st.subheader("ğŸ“Š RÃ©partition par site")
            st.bar_chart(df_total["Site"].value_counts())

            # TÃ©lÃ©chargement CSV
            csv = df_total.to_csv(index=False).encode("utf-8")
            st.download_button(
                label="ğŸ’¾ TÃ©lÃ©charger le CSV",
                data=csv,
                file_name=f"offres_{keyword}_{location}.csv",
                mime="text/csv",
            )
        else:
            st.warning("âŒ Aucune offre trouvÃ©e sur les sites sÃ©lectionnÃ©s.")
